{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qmc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 134\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[38;5;66;03m# Update position\u001b[39;00m\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvelocity\n\u001b[0;32m--> 134\u001b[0m pso \u001b[38;5;241m=\u001b[39m \u001b[43mParticleSwarmOptimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdimensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m pso\u001b[38;5;241m.\u001b[39mrun_optimization()\n",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m, in \u001b[0;36mParticleSwarmOptimization.__init__\u001b[0;34m(self, size, dimensions, w_max, w_min, iter_max)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m=\u001b[39m size\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdimensions \u001b[38;5;241m=\u001b[39m dimensions\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhalton_engine \u001b[38;5;241m=\u001b[39m \u001b[43mqmc\u001b[49m\u001b[38;5;241m.\u001b[39mHalton(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdimensions, scramble\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msobol_engine \u001b[38;5;241m=\u001b[39m qmc\u001b[38;5;241m.\u001b[39mSobol(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdimensions, scramble\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_max \u001b[38;5;241m=\u001b[39m w_max\n",
      "\u001b[0;31mNameError\u001b[0m: name 'qmc' is not defined"
     ]
    }
   ],
   "source": [
    "#https://www.sciencedirect.com/science/article/pii/S0925527310002938\n",
    "#https://www.researchgate.net/publication/297245624_Particle_Swarm_Optimization_Algorithm_and_its_Codes_in_MATLAB\n",
    "#https://www.mdpi.com/1999-4893/17/5/195\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "\n",
    "class ParticleSwarmOptimization:\n",
    "    def __init__(self, size, dimensions=2, w_max=0.9, w_min=0.4, iter_max=100):\n",
    "        self.size = size\n",
    "        self.dimensions = dimensions\n",
    "        self.halton_engine = qmc.Halton(self.dimensions, scramble=False, seed=None)\n",
    "        self.sobol_engine = qmc.Sobol(self.dimensions, scramble=False, seed=None)\n",
    "        self.w_max = w_max\n",
    "        self.w_min = w_min\n",
    "        self.iter_max = iter_max\n",
    "        self.iter = 0\n",
    "        self.population = self.generate_population()\n",
    "        self.velocity = self.initialize_velocity()\n",
    "        self.pbest = self.population  # Initialize pbest as initial population\n",
    "        self.gbest = self.find_gbest()\n",
    "\n",
    "    def fitness(self, positions):\n",
    "    # Rosenbrock function\n",
    "        a = 1\n",
    "        b = 100\n",
    "        if positions.ndim > 1:\n",
    "            x = positions[:, 0]\n",
    "            y = positions[:, 1]\n",
    "        else:\n",
    "            x = positions[0]\n",
    "            y = positions[1]\n",
    "        return (a - x) ** 2 + b * (y - x ** 2) ** 2\n",
    "\n",
    "    def run_optimization(self, convergence_threshold=1e-6):\n",
    "    # Plotting preparation\n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.set_xlabel('x')\n",
    "        ax.set_ylabel('y')\n",
    "        ax.set_zlabel('z')\n",
    "        x = np.linspace(-5, 10, 80)  # Adjust these limits as needed\n",
    "        y = np.linspace(0, 15, 80)  # Adjust these limits as needed\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        Z = self.fitness(np.array([X.ravel(), Y.ravel()]).T).reshape(X.shape)\n",
    "        ax.plot_wireframe(X, Y, Z, color='r', linewidth=0.2)\n",
    "\n",
    "    # Animation image placeholder\n",
    "        images = []\n",
    "\n",
    "        previous_gbest_fitness = self.fitness(np.array([self.gbest]))\n",
    "\n",
    "        while True:  # Run until convergence\n",
    "            self.update_velocity_position()\n",
    "            self.iter += 1\n",
    "            self.gbest = self.find_gbest()\n",
    "            current_gbest_fitness = self.fitness(np.array([self.gbest]))\n",
    "\n",
    "        # Add plot for each generation\n",
    "            image = ax.scatter3D(self.population[:, 0], self.population[:, 1], \n",
    "                                self.fitness(self.population), c='b')\n",
    "            images.append([image])\n",
    "\n",
    "        # Check for convergence\n",
    "            if abs(current_gbest_fitness - previous_gbest_fitness) < convergence_threshold:\n",
    "                break\n",
    "\n",
    "            previous_gbest_fitness = current_gbest_fitness\n",
    "        \n",
    "        ax.text2D(0.05, 0.95, f\"Solution: {self.gbest}\", transform=ax.transAxes)\n",
    "    # Generate the animation image and save\n",
    "        animated_image = animation.ArtistAnimation(fig, images)\n",
    "        animated_image.save('./pso_simple.gif', writer='pillow')\n",
    "\n",
    "    def generate_population(self):\n",
    "        # Generate the initial populations\n",
    "        halton_population = self.halton_engine.random(n=self.size//2)\n",
    "        sobol_population = self.sobol_engine.random(n=self.size//2)\n",
    "\n",
    "        # Combine both populations\n",
    "        initial_population = np.concatenate((halton_population, sobol_population))\n",
    "\n",
    "        return initial_population\n",
    "\n",
    "    def initialize_velocity(self):\n",
    "        # Initialise Velocity\n",
    "        halton_velocity = self.halton_engine.random(n=self.size//2)\n",
    "        sobol_velocity = self.sobol_engine.random(n=self.size//2)\n",
    "        init_velocity = np.concatenate((halton_velocity, sobol_velocity))\n",
    "\n",
    "        return init_velocity\n",
    "\n",
    "    def initialize_weight(self):\n",
    "        # Initialize Inertia Weight\n",
    "        return self.w_max\n",
    "\n",
    "    def calculate_inertia_weight(self):\n",
    "        # Calculate inertia weight\n",
    "        w = self.w_max - ((self.w_max - self.w_min) / self.iter_max) * self.iter\n",
    "        return max(w, self.w_min)  # Ensure w is not less than w_min\n",
    "\n",
    "    def find_gbest(self):\n",
    "        # Find global best position (gbest)\n",
    "        fitness_values = self.fitness(self.population)\n",
    "        gbest_index = np.argmin(fitness_values)\n",
    "        return self.population[gbest_index]\n",
    "\n",
    "    def optimize(self):\n",
    "        while self.iter < self.iter_max:\n",
    "            self.update_velocity_position()\n",
    "            self.iter += 1\n",
    "            self.gbest = self.find_gbest()\n",
    "\n",
    "    def update_velocity_position(self):\n",
    "        # Update velocity and position for each particle\n",
    "        c1 = c2 = 2  # Learning factors\n",
    "        r1 = np.random.rand(self.size, self.dimensions)\n",
    "        r2 = np.random.rand(self.size, self.dimensions)\n",
    "\n",
    "        # Calculate new inertia weight\n",
    "        w = self.calculate_inertia_weight()\n",
    "\n",
    "        # Update velocity\n",
    "        self.velocity = w * self.velocity + c1 * r1 * (self.pbest - self.population) + \\\n",
    "                        c2 * r2 * (self.gbest - self.population)\n",
    "\n",
    "        # Update position\n",
    "        self.population += self.velocity\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pso = ParticleSwarmOptimization(size=100, dimensions=2)\n",
    "pso.run_optimization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/path/to/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModel\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproduction_orders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Data, Product, BillOfMaterial\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnx\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "from enum import Enum\n",
    "from typing import Any, Self\n",
    "import numpy as np\n",
    "from pydantic import BaseModel\n",
    "from src.production_orders import Data, Product, BillOfMaterial\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DAY_MINUTES = 24 * 60\n",
    "\n",
    "\n",
    "class Job(BaseModel):\n",
    "    available_machines: dict[int, int]\n",
    "    dependencies: list[int]\n",
    "    production_order_nr: str\n",
    "    station_settings: dict[str, Any] = dict()\n",
    "    amount: int = 1\n",
    "    days_till_delivery: int = 0\n",
    "\n",
    "\n",
    "class Machine(BaseModel):\n",
    "    name: str\n",
    "    machine_id: int\n",
    "    start_time: int = 0\n",
    "    end_time: int\n",
    "    allow_preemption: bool = False\n",
    "    max_units_per_run: int = 1\n",
    "    minutes_per_run: float\n",
    "\n",
    "\n",
    "class ScheduleError(Exception): ...\n",
    "\n",
    "\n",
    "schedule_type = dict[int, list[tuple[int, int, int]]]\n",
    "\n",
    "\n",
    "class JobShopProblem:\n",
    "    LOW_TARDINESS = None\n",
    "    LOW_TOTAL_SETUP_TIME = None\n",
    "    LOW_MAKESPAN = None\n",
    "\n",
    "    def __init__(self, data: Data, jobs: list[Job], machines: list[Machine]) -> None:\n",
    "        self.data: Data = data\n",
    "        self.jobs: list[Job] = jobs\n",
    "        self.machines: list[Machine] = machines\n",
    "        self.setup_times: np.ndarray = np.zeros((len(jobs), len(jobs)))\n",
    "        self.graph = self._build_graph()\n",
    "\n",
    "    def _build_graph(self) -> nx.DiGraph:\n",
    "        graph = nx.DiGraph()\n",
    "        graph.add_nodes_from([-1, -2] + [x for x in range(len(self.jobs))])\n",
    "        edges = list()\n",
    "        for job_idx, job in enumerate(self.jobs):\n",
    "            if len(job.dependencies) == 0:\n",
    "                edges.append((-1, job_idx))\n",
    "                continue\n",
    "            for dep in job.dependencies:\n",
    "                edges.append((dep, job_idx))\n",
    "        graph.add_edges_from(edges)\n",
    "        for node, outdegree in graph.out_degree(graph.nodes()):\n",
    "            if outdegree == 0 and node >= 0:\n",
    "                graph.add_edge(node, -2)\n",
    "        return graph\n",
    "\n",
    "    def visualize_schedule(\n",
    "        self,\n",
    "        schedule: dict[int, list[tuple[int, int, int]]],\n",
    "        save_path: str | None = None,\n",
    "    ):\n",
    "        \"\"\"Visualizes a schedule.\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(13, 7))\n",
    "        cmap = plt.get_cmap(\"tab20\")\n",
    "        for i, (machine, sch) in enumerate(schedule.items()):\n",
    "            for idx, task in enumerate(sch):\n",
    "                job_id, start_time, end_time = task\n",
    "                if job_id == -1:\n",
    "                    continue\n",
    "                setup_time = self.setup_times[sch[idx - 1][0], job_id]\n",
    "                # Check if we have a preemption job\n",
    "                plot_times = [(start_time, end_time, setup_time)]\n",
    "                if (\n",
    "                    end_time - start_time - setup_time\n",
    "                    > self.jobs[job_id].available_machines[machine]\n",
    "                ):\n",
    "                    plot_times = [\n",
    "                        (\n",
    "                            start_time,\n",
    "                            self.machines[machine].end_time\n",
    "                            + 24 * 60 * (start_time // (24 * 60)),\n",
    "                            setup_time,\n",
    "                        ),\n",
    "                        (\n",
    "                            self.machines[machine].start_time\n",
    "                            + 24 * 60 * (end_time // (24 * 60)),\n",
    "                            end_time,\n",
    "                            0,\n",
    "                        ),\n",
    "                    ]\n",
    "                for start_time, end_time, setup_time in plot_times:\n",
    "                    ax.plot(\n",
    "                        [start_time + setup_time, end_time],\n",
    "                        [i + 1, i + 1],\n",
    "                        linewidth=50,\n",
    "                        label=self.jobs[job_id].production_order_nr,\n",
    "                        solid_capstyle=\"butt\",\n",
    "                        color=cmap(\n",
    "                            int(self.jobs[job_id].production_order_nr.removeprefix(\"P\"))\n",
    "                        ),\n",
    "                    )\n",
    "                    ax.plot(\n",
    "                        [start_time, start_time + setup_time],\n",
    "                        [i + 1, i + 1],\n",
    "                        linewidth=50,\n",
    "                        solid_capstyle=\"butt\",\n",
    "                        color=cmap(\n",
    "                            int(self.jobs[job_id].production_order_nr.removeprefix(\"P\"))\n",
    "                        ),\n",
    "                        alpha=0.5,\n",
    "                    )\n",
    "                    color = \"black\"\n",
    "                    if end_time - self.jobs[job_id].days_till_delivery * 24 * 60 > 0:\n",
    "                        color = \"red\"\n",
    "\n",
    "                    ax.text(\n",
    "                        (start_time + end_time) / 2,\n",
    "                        i + 1,\n",
    "                        self.jobs[job_id].production_order_nr,  # + f\" ({job_id})\",\n",
    "                        va=\"center\",\n",
    "                        ha=\"right\",\n",
    "                        fontsize=11,\n",
    "                        color=color,\n",
    "                    )\n",
    "        flat_schedule = list()\n",
    "        for val in schedule.values():\n",
    "            flat_schedule.extend(val)\n",
    "        max_time = max([t[2] for t in flat_schedule])\n",
    "\n",
    "        day_markers = np.arange(0, max_time, 24 * 60)\n",
    "        day_labels = [f\"{d//24//60}\" for d in day_markers]\n",
    "\n",
    "        plt.xticks(ticks=np.concatenate([day_markers]), labels=day_labels)\n",
    "        plt.yticks(\n",
    "            ticks=np.arange(1, len(schedule) + 1),\n",
    "            labels=[f\"Machine {m}\" for m in schedule.keys()],\n",
    "        )\n",
    "        plt.xlabel(\"Days\")\n",
    "        plt.ylabel(\"Machine\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "        for machine in self.machines:\n",
    "            x_lines_start = np.arange(machine.start_time, max_time, 24 * 60)\n",
    "            plt.vlines(\n",
    "                x_lines_start,\n",
    "                machine.machine_id + 0.5,\n",
    "                machine.machine_id + 1.5,\n",
    "                linestyles=\"dashed\",\n",
    "                color=\"green\",\n",
    "            )\n",
    "            x_lines_end = np.arange(machine.end_time, max_time, 24 * 60)\n",
    "            plt.vlines(\n",
    "                x_lines_end,\n",
    "                machine.machine_id + 0.5,\n",
    "                machine.machine_id + 1.5,\n",
    "                linestyles=\"dashed\",\n",
    "                color=\"red\",\n",
    "            )\n",
    "\n",
    "        if save_path:\n",
    "            plt.savefig(save_path)\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "    @classmethod\n",
    "    def from_data(cls, data: Data) -> Self:\n",
    "        \"\"\"Generate a JobShopProblem from the data provided according to the excel sheet.\n",
    "\n",
    "        Args:\n",
    "            data (Data): The data that is parsed from the excel sheet.\n",
    "\n",
    "        Returns:\n",
    "            Self: The JobShopProblem object.\n",
    "        \"\"\"\n",
    "        sub_jobs: list[Job] = list()\n",
    "        machines: list[Machine] = [\n",
    "            Machine(\n",
    "                name=m.name,\n",
    "                machine_id=idx,\n",
    "                start_time=m.starts_at.hour * 60 + m.starts_at.minute,\n",
    "                end_time=m.stops_at.hour * 60 + m.stops_at.minute,\n",
    "                allow_preemption=(m.name.lower().startswith(\"bottling\")),\n",
    "                max_units_per_run=m.max_units_per_run,\n",
    "                minutes_per_run=m.minutes_per_run,\n",
    "            )\n",
    "            for idx, m in enumerate(data.workstations)\n",
    "        ]\n",
    "        for order in data.production_orders:\n",
    "            # We collect all the products we need to produce\n",
    "            # 1. We get the final product from the products table\n",
    "            # 2. We look in the bill of materials to see if that product has any sub products that are needed\n",
    "            # 3. If it has, we add the sub product from the products table and repeat step 2.\n",
    "            products = list()\n",
    "            curent_product = order.product_id\n",
    "            while curent_product is not None:\n",
    "                product = data.products[curent_product]\n",
    "                bill_of_materials = data.bill_of_materials.get(curent_product, None)\n",
    "                products.append((product, bill_of_materials))\n",
    "                if bill_of_materials:\n",
    "                    curent_product = bill_of_materials.component_id\n",
    "                else:\n",
    "                    curent_product = None\n",
    "            # We reverse the products list, because the products have to be produced in sequential order\n",
    "            products: list[tuple[Product, BillOfMaterial | None]] = products[::-1]\n",
    "            # We split the job into batches of the same product\n",
    "            product_info = list()\n",
    "            # NOTE: amount is different from the amount in the job, since we calcualte the\n",
    "            # amount based on what unit the machine can process\n",
    "            for idx, (prod, _) in enumerate(products):\n",
    "                prod_info = dict()\n",
    "                if idx + 1 < len(products):\n",
    "                    bom = products[idx + 1][1]\n",
    "                else:\n",
    "                    bom = None\n",
    "                amount = order.amount * bom.component_quantity if bom else order.amount\n",
    "                prod_info[\"amount\"] = amount\n",
    "                # HACK: we are shortening the name by 1 since it says bottle and not bottling, which the machine name is\n",
    "                prod_info[\"machines\"] = [\n",
    "                    m.machine_id\n",
    "                    for m in machines\n",
    "                    if m.name.lower().startswith(prod.workstation_type[:-1])\n",
    "                ]\n",
    "                # HACK: the batch sizes are not calculated per machine, so if two machines\n",
    "                # that process the same job has different ones, we will take the one that has\n",
    "                # the lowest capacity to calculate the batch size\n",
    "                min_max_units_per_run = min(\n",
    "                    [machines[m].max_units_per_run for m in prod_info[\"machines\"]]\n",
    "                )\n",
    "                prod_info[\"batches\"] = max(int(amount // min_max_units_per_run), 1)\n",
    "                prod_info[\"batches_amount\"] = min_max_units_per_run\n",
    "                remainder = int(amount % min_max_units_per_run)\n",
    "                prod_info[\"batches_remainder\"] = (\n",
    "                    remainder if remainder > 0 else min_max_units_per_run\n",
    "                )\n",
    "                product_info.append(prod_info)\n",
    "            # We calculate the correct batch size, or in other words the job that has\n",
    "            # the smallest batch amount size, since that will be the bottle neck.\n",
    "            # However, we ignore if the jobs can be run independently, since we will just make that into\n",
    "            # one batch\n",
    "            batch_info = min(\n",
    "                product_info,\n",
    "                key=lambda x: x[\"batches_amount\"] if x[\"batches_amount\"] > 1 else 10e4,\n",
    "            )\n",
    "            for i in range(batch_info[\"batches\"]):\n",
    "                for idx, prod in enumerate(product_info):\n",
    "                    dependencies = list()\n",
    "                    if idx > 0:\n",
    "                        dependencies.append(len(sub_jobs) - 1)\n",
    "\n",
    "                    amount = prod[\"amount\"] // batch_info[\"batches\"]\n",
    "                    if i == batch_info[\"batches\"] - 1:\n",
    "                        amount = prod[\"amount\"] % batch_info[\"batches\"]\n",
    "                        if amount == 0:\n",
    "                            amount = prod[\"amount\"] // batch_info[\"batches\"]\n",
    "\n",
    "                    sub_jobs.append(\n",
    "                        Job(\n",
    "                            available_machines={\n",
    "                                m: data.workstations[m].minutes_per_run * amount\n",
    "                                if data.workstations[m].max_units_per_run == 1\n",
    "                                else data.workstations[m].minutes_per_run\n",
    "                                for m in prod[\"machines\"]\n",
    "                            },\n",
    "                            dependencies=dependencies,\n",
    "                            production_order_nr=order.production_order_nr,\n",
    "                            station_settings={\n",
    "                                \"taste\": products[idx][0].setting_taste,\n",
    "                                \"bottle_size\": products[idx][0].setting_bottle_size,\n",
    "                            },\n",
    "                            amount=amount,\n",
    "                            days_till_delivery=order.days_till_delivery,\n",
    "                        )\n",
    "                    )\n",
    "        jssp = cls(data=data, jobs=sub_jobs, machines=machines)\n",
    "\n",
    "        # Set setup-times\n",
    "        for j1_idx, j1 in enumerate(jssp.jobs):\n",
    "            for j2_idx, j2 in enumerate(jssp.jobs):\n",
    "                if j1 == j2 or j1.production_order_nr == j2.production_order_nr:\n",
    "                    continue\n",
    "                if j1.station_settings[\"taste\"] != j2.station_settings[\"taste\"]:\n",
    "                    jssp.setup_times[j1_idx, j2_idx] += jssp.data.workstations[\n",
    "                        list(j1.available_machines.keys())[0]\n",
    "                    ].minutes_changeover_time_taste\n",
    "\n",
    "                if (\n",
    "                    j1.station_settings[\"bottle_size\"]\n",
    "                    != j2.station_settings[\"bottle_size\"]\n",
    "                ):\n",
    "                    jssp.setup_times[j1_idx, j2_idx] += jssp.data.workstations[\n",
    "                        list(j1.available_machines.keys())[0]\n",
    "                    ].minutes_changeover_time_bottle_size\n",
    "\n",
    "        return jssp\n",
    "\n",
    "    def make_schedule(\n",
    "        self, job_order: list[int], machine_assignment: list[int]\n",
    "    ) -> schedule_type:\n",
    "        \"\"\"Create a schedule based on a give job order and machine assignment.\n",
    "\n",
    "        Note that the job_order is relative, and machine_assignment is absolute. That means that\n",
    "        the machine_assignment have at index i the machine assignment for job i. While the job_order\n",
    "        at index i is the job that should be done at position i in relation to the other jobs in the list.\n",
    "\n",
    "        Args:\n",
    "            job_order (list[int]): the order of the jobs that should be done\n",
    "            machine_assignment (list[int]): what machine job i should be done on\n",
    "\n",
    "        Raises:\n",
    "            ScheduleError: raised if the job order or machine assignment is incorrect\n",
    "\n",
    "        Returns:\n",
    "            dict[int, list[tuple[int, int, int]]]: the schedule for each machine with the job id, start time and end time\n",
    "                relative to midnight of day 0.\n",
    "        \"\"\"\n",
    "        # Contains the schedule for each machine\n",
    "        schedule: dict[int, list[tuple[int, int, int]]] = {\n",
    "            m.machine_id: [(-1, 0, m.start_time)] for m in self.machines\n",
    "        }\n",
    "\n",
    "        # Contains the machine, start time and end time for each job\n",
    "        job_schedule: dict[int, tuple[int, int, int]] = dict()\n",
    "\n",
    "        for task_idx in job_order:\n",
    "            task: Job = self.jobs[task_idx]\n",
    "            machine_idx = machine_assignment[task_idx]\n",
    "            if machine_idx not in task.available_machines:\n",
    "                raise ScheduleError(\n",
    "                    f\"Machine {machine_idx} not available for task {task_idx}\"\n",
    "                )\n",
    "            machine = self.machines[machine_idx]\n",
    "\n",
    "            relevant_task: list[tuple[int, int, int]] = list()\n",
    "\n",
    "            # Get the last job on the same machine\n",
    "            latest_job_on_same_machine = schedule[machine_idx][-1]\n",
    "            relevant_task.append(latest_job_on_same_machine)\n",
    "\n",
    "            # Check for dependencies\n",
    "            if len(task.dependencies) > 0:\n",
    "                for dep in task.dependencies:\n",
    "                    if dep_task := job_schedule.get(dep, None):\n",
    "                        relevant_task.append(dep_task)\n",
    "                    else:\n",
    "                        raise ScheduleError(\n",
    "                            f\"Dependency {dep} not scheduled before {task_idx}\"\n",
    "                        )\n",
    "\n",
    "            # Get the start time of the task\n",
    "            start_time = max([task[2] for task in relevant_task])\n",
    "\n",
    "            task_duration: int = int(\n",
    "                task.available_machines[machine_idx]\n",
    "                + self.setup_times[latest_job_on_same_machine[0], task_idx]\n",
    "            )\n",
    "            # If task is schedule before the machine starts, we move it to the start time\n",
    "            if start_time % DAY_MINUTES < machine.start_time:\n",
    "                start_time = (\n",
    "                    machine.start_time + (start_time // DAY_MINUTES) * DAY_MINUTES\n",
    "                )\n",
    "\n",
    "            # If the task ends after the machine stops, we move it to the next day, unless we allow preemption.\n",
    "            # If we allow preemption we will just continue with the work the next day\n",
    "            if start_time % DAY_MINUTES + task_duration > machine.end_time:\n",
    "                # If we allow for preemption we will just add to the duration the time inbetween start and end time\n",
    "                if machine.allow_preemption:\n",
    "                    task_duration += DAY_MINUTES - machine.end_time + machine.start_time\n",
    "                else:\n",
    "                    start_time = (\n",
    "                        machine.start_time\n",
    "                        + (start_time // DAY_MINUTES + 1) * DAY_MINUTES\n",
    "                    )\n",
    "\n",
    "            end_time = start_time + task_duration\n",
    "            schedule[machine_idx].append((task_idx, start_time, end_time))\n",
    "            job_schedule[task_idx] = (machine_idx, start_time, end_time)\n",
    "\n",
    "        return schedule\n",
    "\n",
    "    def makespan(self, schedule: schedule_type) -> int:\n",
    "        \"\"\"Calculate the makespan of the schedule.\n",
    "\n",
    "        Args:\n",
    "            schedule (schedule): the schedule that should be evaluated\n",
    "\n",
    "        Returns:\n",
    "            int: the makespan of the schedule\n",
    "        \"\"\"\n",
    "        return max([task[2] for machine in schedule.values() for task in machine])\n",
    "\n",
    "    def tardiness(self, schedule: schedule_type) -> int:\n",
    "        \"\"\"Calculate the tardiness of the schedule. The tardiness is the number of sub jobs that are late.\n",
    "\n",
    "        As soon as just 1 sub job is late the whole order is late, and should be penalized.\n",
    "\n",
    "        Args:\n",
    "            schedule (schedule): the schedule that should be evaluated\n",
    "\n",
    "        Returns:\n",
    "            int: the tardiness of the schedule\n",
    "        \"\"\"\n",
    "        production_order_lateness = {\n",
    "            order.production_order_nr: [] for order in self.data.production_orders\n",
    "        }\n",
    "        for machine in schedule.values():\n",
    "            for task in machine:\n",
    "                production_order_lateness[\n",
    "                    self.jobs[task[0]].production_order_nr\n",
    "                ].append(\n",
    "                    max(\n",
    "                        task[2] - self.jobs[task[0]].days_till_delivery * DAY_MINUTES, 0\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        tardiness = 0\n",
    "        for lateness in production_order_lateness.values():\n",
    "            if any([l > 0 for l in lateness]):\n",
    "                tardiness += np.average(lateness) * len(lateness)\n",
    "        return int(tardiness)\n",
    "\n",
    "    def total_setup_time(self, schedule: schedule_type) -> int:\n",
    "        \"\"\"Calculate the total setup time of the schedule.\n",
    "\n",
    "        Args:\n",
    "            schedule (schedule): the schedule that should be evaluated\n",
    "\n",
    "        Returns:\n",
    "            int: the total setup time of the schedule\n",
    "        \"\"\"\n",
    "        setup_time = 0\n",
    "        for machine in schedule.values():\n",
    "            for idx, task in enumerate(machine):\n",
    "                if idx > 0:\n",
    "                    setup_time += self.setup_times[machine[idx - 1][0], task[0]]\n",
    "        return setup_time\n",
    "\n",
    "    def custom_objective(self, schedule: schedule_type) -> float:\n",
    "        tardiness = self.tardiness(schedule)\n",
    "        total_setup_time = self.total_setup_time(schedule)\n",
    "        makespan = self.makespan(schedule)\n",
    "        if self.LOW_TARDINESS is None:\n",
    "            self.LOW_TARDINESS = 1600.0\n",
    "        if self.LOW_TOTAL_SETUP_TIME is None:\n",
    "            self.LOW_TOTAL_SETUP_TIME = 10.0\n",
    "        if self.LOW_MAKESPAN is None:\n",
    "            self.LOW_MAKESPAN = 3600.0\n",
    "\n",
    "        return (\n",
    "            (tardiness - self.LOW_TARDINESS) / self.LOW_TARDINESS\n",
    "            + (total_setup_time - self.LOW_TOTAL_SETUP_TIME) / self.LOW_TOTAL_SETUP_TIME\n",
    "            + (makespan - self.LOW_MAKESPAN) / self.LOW_MAKESPAN\n",
    "        )\n",
    "\n",
    "\n",
    "class ObjectiveFunction(Enum):\n",
    "    CUSTOM_OBJECTIVE = 0\n",
    "    MAKESPAN = 1\n",
    "    TARDINESS = 2\n",
    "    TOTAL_SETUP_TIME = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/akshatnagar/Documents/GitHub/bachelors-thesis/AKSHAT/PSO\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/path/to/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting src\n",
      "  Using cached src-0.0.7.zip (6.3 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: src\n",
      "  Building wheel for src (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for src \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[68 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib\n",
      "  \u001b[31m   \u001b[0m creating build/lib/src\n",
      "  \u001b[31m   \u001b[0m copying src/__init__.py -> build/lib/src\n",
      "  \u001b[31m   \u001b[0m running egg_info\n",
      "  \u001b[31m   \u001b[0m writing src.egg-info/PKG-INFO\n",
      "  \u001b[31m   \u001b[0m writing dependency_links to src.egg-info/dependency_links.txt\n",
      "  \u001b[31m   \u001b[0m writing requirements to src.egg-info/requires.txt\n",
      "  \u001b[31m   \u001b[0m writing top-level names to src.egg-info/top_level.txt\n",
      "  \u001b[31m   \u001b[0m reading manifest file 'src.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m reading manifest template 'MANIFEST.in'\n",
      "  \u001b[31m   \u001b[0m adding license file 'LICENSE.rst'\n",
      "  \u001b[31m   \u001b[0m writing manifest file 'src.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 353, in <module>\n",
      "  \u001b[31m   \u001b[0m     main()\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 335, in main\n",
      "  \u001b[31m   \u001b[0m     json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "  \u001b[31m   \u001b[0m                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 251, in build_wheel\n",
      "  \u001b[31m   \u001b[0m     return _build_backend().build_wheel(wheel_directory, config_settings,\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/t5/1yc3fjpx3rx98hxkjxzdpn240000gn/T/pip-build-env-_pj93iha/overlay/lib/python3.12/site-packages/setuptools/build_meta.py\", line 410, in build_wheel\n",
      "  \u001b[31m   \u001b[0m     return self._build_with_temp_dir(\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/t5/1yc3fjpx3rx98hxkjxzdpn240000gn/T/pip-build-env-_pj93iha/overlay/lib/python3.12/site-packages/setuptools/build_meta.py\", line 395, in _build_with_temp_dir\n",
      "  \u001b[31m   \u001b[0m     self.run_setup()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/t5/1yc3fjpx3rx98hxkjxzdpn240000gn/T/pip-build-env-_pj93iha/overlay/lib/python3.12/site-packages/setuptools/build_meta.py\", line 487, in run_setup\n",
      "  \u001b[31m   \u001b[0m     super().run_setup(setup_script=setup_script)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/t5/1yc3fjpx3rx98hxkjxzdpn240000gn/T/pip-build-env-_pj93iha/overlay/lib/python3.12/site-packages/setuptools/build_meta.py\", line 311, in run_setup\n",
      "  \u001b[31m   \u001b[0m     exec(code, locals())\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 70, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/t5/1yc3fjpx3rx98hxkjxzdpn240000gn/T/pip-build-env-_pj93iha/overlay/lib/python3.12/site-packages/setuptools/__init__.py\", line 104, in setup\n",
      "  \u001b[31m   \u001b[0m     return distutils.core.setup(**attrs)\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/t5/1yc3fjpx3rx98hxkjxzdpn240000gn/T/pip-build-env-_pj93iha/overlay/lib/python3.12/site-packages/setuptools/_distutils/core.py\", line 184, in setup\n",
      "  \u001b[31m   \u001b[0m     return run_commands(dist)\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/t5/1yc3fjpx3rx98hxkjxzdpn240000gn/T/pip-build-env-_pj93iha/overlay/lib/python3.12/site-packages/setuptools/_distutils/core.py\", line 200, in run_commands\n",
      "  \u001b[31m   \u001b[0m     dist.run_commands()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/t5/1yc3fjpx3rx98hxkjxzdpn240000gn/T/pip-build-env-_pj93iha/overlay/lib/python3.12/site-packages/setuptools/_distutils/dist.py\", line 969, in run_commands\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/t5/1yc3fjpx3rx98hxkjxzdpn240000gn/T/pip-build-env-_pj93iha/overlay/lib/python3.12/site-packages/setuptools/dist.py\", line 967, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/t5/1yc3fjpx3rx98hxkjxzdpn240000gn/T/pip-build-env-_pj93iha/overlay/lib/python3.12/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/t5/1yc3fjpx3rx98hxkjxzdpn240000gn/T/pip-build-env-_pj93iha/normal/lib/python3.12/site-packages/wheel/bdist_wheel.py\", line 370, in run\n",
      "  \u001b[31m   \u001b[0m     install = self.reinitialize_command(\"install\", reinit_subcommands=True)\n",
      "  \u001b[31m   \u001b[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/t5/1yc3fjpx3rx98hxkjxzdpn240000gn/T/pip-build-env-_pj93iha/overlay/lib/python3.12/site-packages/setuptools/__init__.py\", line 221, in reinitialize_command\n",
      "  \u001b[31m   \u001b[0m     cmd = _Command.reinitialize_command(self, command, reinit_subcommands)\n",
      "  \u001b[31m   \u001b[0m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/t5/1yc3fjpx3rx98hxkjxzdpn240000gn/T/pip-build-env-_pj93iha/overlay/lib/python3.12/site-packages/setuptools/_distutils/cmd.py\", line 309, in reinitialize_command\n",
      "  \u001b[31m   \u001b[0m     return self.distribution.reinitialize_command(command, reinit_subcommands)\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/t5/1yc3fjpx3rx98hxkjxzdpn240000gn/T/pip-build-env-_pj93iha/overlay/lib/python3.12/site-packages/setuptools/_distutils/dist.py\", line 953, in reinitialize_command\n",
      "  \u001b[31m   \u001b[0m     for sub in command.get_sub_commands():\n",
      "  \u001b[31m   \u001b[0m                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/t5/1yc3fjpx3rx98hxkjxzdpn240000gn/T/pip-build-env-_pj93iha/overlay/lib/python3.12/site-packages/setuptools/_distutils/cmd.py\", line 327, in get_sub_commands\n",
      "  \u001b[31m   \u001b[0m     if method is None or method(self):\n",
      "  \u001b[31m   \u001b[0m                          ^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/t5/1yc3fjpx3rx98hxkjxzdpn240000gn/T/pip-build-env-_pj93iha/overlay/lib/python3.12/site-packages/setuptools/_distutils/command/install.py\", line 787, in has_lib\n",
      "  \u001b[31m   \u001b[0m     self.distribution.has_pure_modules() or self.distribution.has_ext_modules()\n",
      "  \u001b[31m   \u001b[0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m AttributeError: 'NoneType' object has no attribute 'has_pure_modules'\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[31m  ERROR: Failed building wheel for src\u001b[0m\u001b[31m\n",
      "\u001b[0mFailed to build src\n",
      "\u001b[31mERROR: Could not build wheels for src, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "545bd306290374aa22ae097f2b15647638e03887f029acba98737d211d2003a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
